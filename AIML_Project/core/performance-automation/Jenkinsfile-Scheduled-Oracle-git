// Schedule: Daily at 2 AM
// Cron format: minute hour day month dayofweek
// 0 2 * * * = Every day at 2:00 AM
pipeline {
    agent any
    
    // DAILY SCHEDULE - Runs every day at 2 AM
    triggers {
        cron('0 2 * * *')  // Daily at 2 AM
        // Other examples:
        // cron('0 2 * * 1-5')  // Weekdays at 2 AM
        // cron('0 */6 * * *')  // Every 6 hours
        // cron('H 2 * * *')    // Daily at 2 AM (distributed)
    }
    
    parameters {
        string(
            name: 'PC_HOST',
            defaultValue: 'pc-server.example.com',
            description: 'Performance Center Host (without https://)'
        )
        string(
            name: 'PC_PORT',
            defaultValue: '443',
            description: 'Performance Center Port'
        )
        string(
            name: 'PC_DOMAIN',
            defaultValue: 'DEFAULT',
            description: 'Performance Center Domain'
        )
        string(
            name: 'PC_PROJECT',
            defaultValue: 'MyProject',
            description: 'Performance Center Project Name'
        )
        string(
            name: 'TEST_ID',
            defaultValue: '1',
            description: 'Performance Center Test ID to execute'
        )
        string(
            name: 'TEST_DURATION',
            defaultValue: '600',
            description: 'Test duration in seconds'
        )
        string(
            name: 'POST_RUN_ACTION',
            defaultValue: 'Collate and Analyze',
            description: 'Post run action'
        )
        string(
            name: 'POLL_INTERVAL',
            defaultValue: '30',
            description: 'Status check interval in seconds'
        )
        string(
            name: 'EMAIL_RECIPIENTS',
            defaultValue: 'team@example.com',
            description: 'Email recipients (comma-separated)'
        )
        // Oracle Database Parameters
        string(
            name: 'ORACLE_HOST',
            defaultValue: 'oracle-server.example.com',
            description: 'Oracle database host'
        )
        string(
            name: 'ORACLE_PORT',
            defaultValue: '1521',
            description: 'Oracle database port'
        )
        string(
            name: 'ORACLE_SERVICE',
            defaultValue: 'ORCL',
            description: 'Oracle service name'
        )
        booleanParam(
            name: 'LOAD_TO_ORACLE',
            defaultValue: true,
            description: 'Load results to Oracle database'
        )
    }
    
    environment {
        RUN_ID = ""
        RESULT_ID = ""
        FINAL_STATUS = ""
    }
    
    stages {
        stage('Preparation') {
            steps {
                script {
                    echo "=========================================="
                    echo "PC Automation - Scheduled Run"
                    echo "=========================================="
                    echo "Build: #${BUILD_NUMBER}"
                    echo "Triggered: ${currentBuild.getBuildCauses()[0].shortDescription}"
                    echo "PC Host: ${params.PC_HOST}"
                    echo "Test ID: ${params.TEST_ID}"
                    echo "Oracle Integration: ${params.LOAD_TO_ORACLE}"
                    echo "=========================================="
                    
                    sh "mkdir -p ${WORKSPACE}/results ${WORKSPACE}/scripts"
                    
                    // Copy Python scripts to workspace
                    sh """
                        # These scripts should be in your Jenkins workspace or SCM
                        # For now, we'll create them inline
                        echo "Python scripts will be created inline"
                    """
                }
            }
        }
        
        // ... [Keep all existing stages: Authentication, Trigger, Monitor, Download, Extract] ...
        // ... [Copy from previous Jenkinsfile-PC-24.1-PRODUCTION] ...
        
        stage('Parse Report and Extract Metrics') {
            when {
                expression { params.LOAD_TO_ORACLE }
            }
            steps {
                script {
                    echo ""
                    echo "=" * 60
                    echo "Parsing PC Report"
                    echo "=" * 60
                    
                    def runId = sh(script: "cat ${WORKSPACE}/results/run_id.txt 2>/dev/null || echo ''", returnStdout: true).trim()
                    def mainReport = sh(
                        script: "find ${WORKSPACE}/results -name 'index.html' -o -name 'report.html' -o -name '*.html' | head -1",
                        returnStdout: true
                    ).trim()
                    
                    if (!mainReport) {
                        echo "âš  No HTML report found, skipping parsing"
                        return
                    }
                    
                    echo "Report file: ${mainReport}"
                    
                    // Install required Python packages
                    sh """
                        pip3 install --user beautifulsoup4 lxml --break-system-packages 2>/dev/null || \
                        pip3 install --user beautifulsoup4 lxml || \
                        echo "BeautifulSoup4 may already be installed"
                    """
                    
                    // Create the parser script inline
                    sh """
cat > ${WORKSPACE}/scripts/parse_report.py << 'PYEOF'
#!/usr/bin/env python3
import sys
import json
from bs4 import BeautifulSoup
import re

def parse_html_report(report_path):
    with open(report_path, 'r', encoding='utf-8', errors='ignore') as f:
        html = f.read()
    
    soup = BeautifulSoup(html, 'html.parser')
    transactions = []
    
    # Find all tables
    for table in soup.find_all('table'):
        rows = table.find_all('tr')
        if len(rows) < 2:
            continue
        
        # Get headers
        headers = [th.get_text().strip().lower() for th in rows[0].find_all(['th', 'td'])]
        
        # Check if this looks like a transaction table
        if not any(keyword in ' '.join(headers) for keyword in ['transaction', 'response', 'average']):
            continue
        
        # Parse data rows
        for row in rows[1:]:
            cells = [td.get_text().strip() for td in row.find_all('td')]
            if len(cells) < 2:
                continue
            
            # Try to extract transaction data
            txn = {
                'transaction_name': cells[0] if len(cells) > 0 else None,
                'avg_response_time': parse_number(cells[1]) if len(cells) > 1 else None,
                'min_response_time': parse_number(cells[2]) if len(cells) > 2 else None,
                'max_response_time': parse_number(cells[3]) if len(cells) > 3 else None,
                'percentile_90': parse_number(cells[4]) if len(cells) > 4 else None,
                'percentile_95': parse_number(cells[5]) if len(cells) > 5 else None,
                'error_rate': parse_number(cells[6]) if len(cells) > 6 else None,
                'transaction_count': int(parse_number(cells[7])) if len(cells) > 7 else None
            }
            
            if txn['transaction_name'] and txn['avg_response_time']:
                transactions.append(txn)
    
    return transactions

def parse_number(value):
    try:
        cleaned = value.replace(',', '').replace('%', '').strip()
        return float(cleaned)
    except:
        return None

if __name__ == '__main__':
    report_path = sys.argv[1]
    output_path = sys.argv[2]
    
    transactions = parse_html_report(report_path)
    
    data = {
        'transactions': transactions,
        'count': len(transactions)
    }
    
    with open(output_path, 'w') as f:
        json.dump(data, f, indent=2)
    
    print(f"Parsed {len(transactions)} transactions")
    for txn in transactions:
        print(f"  - {txn['transaction_name']}: {txn['avg_response_time']} ms")
PYEOF

chmod +x ${WORKSPACE}/scripts/parse_report.py
"""
                    
                    // Run parser
                    sh """
                        python3 ${WORKSPACE}/scripts/parse_report.py \
                        "${mainReport}" \
                        "${WORKSPACE}/results/transactions_data.json"
                    """
                    
                    // Read and display results
                    def jsonData = readFile("${WORKSPACE}/results/transactions_data.json")
                    def parsedData = readJSON text: jsonData
                    
                    echo ""
                    echo "âœ“ Parsed ${parsedData.count} transactions:"
                    parsedData.transactions.each { txn ->
                        echo "  - ${txn.transaction_name}: ${txn.avg_response_time} ms"
                    }
                }
            }
        }
        
        stage('Load to Oracle Database') {
            when {
                expression { params.LOAD_TO_ORACLE }
            }
            steps {
                script {
                    echo ""
                    echo "=" * 60
                    echo "Loading Data to Oracle"
                    echo "=" * 60
                    
                    def runId = sh(script: "cat ${WORKSPACE}/results/run_id.txt", returnStdout: true).trim()
                    def resultId = sh(script: "cat ${WORKSPACE}/results/result_id.txt 2>/dev/null || echo ''", returnStdout: true).trim()
                    def finalStatus = sh(script: "cat ${WORKSPACE}/results/final_status.txt 2>/dev/null || echo 'UNKNOWN'", returnStdout: true).trim()
                    
                    // Install cx_Oracle
                    sh """
                        pip3 install --user cx_Oracle --break-system-packages 2>/dev/null || \
                        pip3 install --user cx_Oracle || \
                        echo "cx_Oracle may already be installed"
                    """
                    
                    // Create Oracle loader script
                    sh """
cat > ${WORKSPACE}/scripts/load_oracle.py << 'PYEOF'
#!/usr/bin/env python3
import sys
import json
import cx_Oracle
from datetime import datetime

def load_to_oracle(oracle_dsn, oracle_user, oracle_pass, json_file, run_info):
    # Connect
    conn = cx_Oracle.connect(oracle_user, oracle_pass, oracle_dsn)
    cursor = conn.cursor()
    
    # Read JSON
    with open(json_file) as f:
        data = json.load(f)
    
    # Insert test run
    try:
        cursor.execute('''
            INSERT INTO PC_TEST_RUNS 
            (RUN_ID, TEST_ID, BUILD_NUMBER, TEST_STATUS, TEST_DURATION, PC_HOST, PC_PROJECT, RUN_DATE)
            VALUES (:1, :2, :3, :4, :5, :6, :7, SYSDATE)
        ''', (
            int(run_info['run_id']),
            int(run_info['test_id']),
            run_info['build_number'],
            run_info['status'],
            int(run_info['duration']),
            run_info['pc_host'],
            run_info['pc_project']
        ))
        print(f"âœ“ Inserted run {run_info['run_id']}")
    except cx_Oracle.IntegrityError:
        print(f"Run {run_info['run_id']} already exists")
    
    # Insert transactions
    count = 0
    for txn in data['transactions']:
        try:
            cursor.execute('''
                INSERT INTO PC_TRANSACTIONS 
                (RUN_ID, TRANSACTION_NAME, AVG_RESPONSE_TIME, MIN_RESPONSE_TIME, 
                 MAX_RESPONSE_TIME, PERCENTILE_90, PERCENTILE_95, ERROR_RATE, TRANSACTION_COUNT)
                VALUES (:1, :2, :3, :4, :5, :6, :7, :8, :9)
            ''', (
                int(run_info['run_id']),
                txn['transaction_name'],
                txn.get('avg_response_time'),
                txn.get('min_response_time'),
                txn.get('max_response_time'),
                txn.get('percentile_90'),
                txn.get('percentile_95'),
                txn.get('error_rate'),
                txn.get('transaction_count')
            ))
            count += 1
        except Exception as e:
            print(f"Error inserting {txn['transaction_name']}: {e}")
    
    conn.commit()
    cursor.close()
    conn.close()
    
    print(f"âœ“ Loaded {count} transactions to Oracle")
    return count

if __name__ == '__main__':
    oracle_dsn = sys.argv[1]
    oracle_user = sys.argv[2]
    oracle_pass = sys.argv[3]
    json_file = sys.argv[4]
    run_id = sys.argv[5]
    test_id = sys.argv[6]
    build_num = sys.argv[7]
    status = sys.argv[8]
    duration = sys.argv[9]
    pc_host = sys.argv[10]
    pc_project = sys.argv[11]
    
    run_info = {
        'run_id': run_id,
        'test_id': test_id,
        'build_number': build_num,
        'status': status,
        'duration': duration,
        'pc_host': pc_host,
        'pc_project': pc_project
    }
    
    count = load_to_oracle(oracle_dsn, oracle_user, oracle_pass, json_file, run_info)
    sys.exit(0 if count > 0 else 1)
PYEOF

chmod +x ${WORKSPACE}/scripts/load_oracle.py
"""
                    
                    // Load to Oracle
                    withCredentials([usernamePassword(
                        credentialsId: 'oracle-credentials',
                        usernameVariable: 'ORACLE_USER',
                        passwordVariable: 'ORACLE_PASS'
                    )]) {
                        
                        def oracleDSN = "${params.ORACLE_HOST}:${params.ORACLE_PORT}/${params.ORACLE_SERVICE}"
                        
                        echo "Oracle DSN: ${oracleDSN}"
                        echo "Run ID: ${runId}"
                        
                        sh """
                            python3 ${WORKSPACE}/scripts/load_oracle.py \
                            "${oracleDSN}" \
                            "${ORACLE_USER}" \
                            "${ORACLE_PASS}" \
                            "${WORKSPACE}/results/transactions_data.json" \
                            "${runId}" \
                            "${params.TEST_ID}" \
                            "${BUILD_NUMBER}" \
                            "${finalStatus}" \
                            "${params.TEST_DURATION}" \
                            "${params.PC_HOST}" \
                            "${params.PC_PROJECT}"
                        """
                    }
                    
                    echo "âœ“ Data loaded to Oracle successfully"
                }
            }
        }
        
        stage('Generate Summary Report') {
            steps {
                script {
                    // ... Keep existing summary generation ...
                }
            }
        }
        
        stage('Archive Results') {
            steps {
                script {
                    archiveArtifacts artifacts: 'results/**/*', allowEmptyArchive: false, fingerprint: true
                    
                    echo "âœ“ Results archived!"
                    echo "ðŸ“„ Summary: ${BUILD_URL}artifact/results/performance_report.html"
                    echo "ðŸ“Š Transaction Data: ${BUILD_URL}artifact/results/transactions_data.json"
                }
            }
        }
        
        stage('Send Email Notification') {
            when {
                expression { params.EMAIL_RECIPIENTS != 'team@example.com' }
            }
            steps {
                script {
                    // ... Keep existing email notification ...
                    // Add Oracle status to email
                }
            }
        }
    }
    
    post {
        success {
            script {
                def runId = sh(script: "cat ${WORKSPACE}/results/run_id.txt 2>/dev/null || echo 'N/A'", returnStdout: true).trim()
                
                echo ""
                echo "=========================================="
                echo "âœ“ SCHEDULED RUN COMPLETED!"
                echo "=========================================="
                echo "Build: #${BUILD_NUMBER}"
                echo "Run ID: ${runId}"
                echo "Oracle: ${params.LOAD_TO_ORACLE ? 'Loaded' : 'Skipped'}"
                echo "Next Run: ${currentBuild.getNextBuild()}"
                echo "=========================================="
            }
        }
        
        failure {
            echo "âœ— Scheduled run failed - check logs"
        }
    }
}
